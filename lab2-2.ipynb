{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint as pp\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empezamos  inicializando los vectores Theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Definamos los tamaños de cada capa. La de input sera de 784, la hidden layer de 258, la output de 10 (existen 10 posibles clasificaciones).\n",
    "layer_sizes={'ilayer':28, 'hlayer':7, 'olayer':10}\n",
    "##Thetas\n",
    "#Solo tenemos una hidden layer, por lo que tenemos un theta de I a Z(1), y una de Z(1) a O.\n",
    "#Les generamos valores aleatorios entre 0 y 1.\n",
    "thetaI_Z = np.random.rand(layer_sizes['ilayer'], layer_sizes['hlayer'])\n",
    "thetaZ_O = np.random.rand(layer_sizes['hlayer'], layer_sizes['olayer'])\n",
    "thetas_dict = {'Theta I_Z': thetaI_Z,\n",
    "              'Theta Z_O': thetaZ_O}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Definamos las funciones a utilizar.\n",
    "def sigmoid(Z):\n",
    "    #print (1/(1+np.exp(-Z)))\n",
    "    return (1/(1+np.exp(-Z)))\n",
    "def sigmoid_derivative(Z):\n",
    "    #print(Z, 1-Z)\n",
    "    return (Z)*(1-(Z))\n",
    "def forward_propagate(X, activation_function=sigmoid):\n",
    "    ##...hay una discusion por hacerse sobre utilizar diccionarios dinamicos para theta de tamaño variable..\n",
    "    ##..por ahora los haremos constantes\n",
    "    \n",
    "    #print(X)\n",
    "    #print(thetas_dict['Theta I_Z'])\n",
    "    Z_1 = np.dot(X, thetas_dict['Theta I_Z'])\n",
    "    Z_2 = activation_function(Z_1) ##Necesitamos una funcion de activacion, por default usaremos sigmoide.\n",
    "    #print(Z_2)\n",
    "    Z_3 = np.dot(Z_2, thetas_dict['Theta Z_O'])\n",
    "    #print(Z_3)\n",
    "    activation = sigmoid(Z_3)\n",
    "    results_dict = {'Z1': Z_1,\n",
    "                   'Z2': Z_2,\n",
    "                   'Z3': Z_3,\n",
    "                   'Activation': activation}\n",
    "    return results_dict\n",
    "\n",
    "def backprop(X, y, forward_prop_results, activation_derivative=sigmoid_derivative, debug=False, ld=0.0001):\n",
    "    ##Desenpaquemos valores\n",
    "    #Fprop, al final solo usamos estos dos, pero sirve tener lo otro para debug.\n",
    "    fprop_output = forward_prop_results['Activation']\n",
    "    fprop_Z2 = forward_prop_results['Z2']\n",
    "    #Thetas\n",
    "    #theta_1 = thetas_dict['Theta I_Z']\n",
    "    #theta_2 =  \n",
    "    ##Errores de salida\n",
    "    output_error = fprop_output-y\n",
    "    sigmodp_fo=activation_derivative(fprop_output)\n",
    "    output_smalldelta = output_error * sigmodp_fo\n",
    "    ##Errores de hLayer\n",
    "    hlayer_error = output_smalldelta.dot(thetas_dict['Theta Z_O'].T)\n",
    "    sigmoidp_hl = activation_derivative(fprop_Z2)\n",
    "    hlayer_smalldelta = hlayer_error* sigmoidp_hl*ld\n",
    "    if debug:\n",
    "        pass\n",
    "        #np.savetxt('deltas.txt', output_smalldelta)\n",
    "        #print(\"Smalldelta:\",hlayer_smalldelta, \"\\nError\", hlayer_error,\"\\nSprime\", sigmoidp_hl)\n",
    "        #print(\"Output Smalldelta:\",output_smalldelta, \"\\noError\", output_error,\"\\nSprime\", sigmodp_fo)\n",
    "    \n",
    "    ##Ajustes a theta\n",
    "    #Creemos un nuevo dict para no modificar el original (esto se ignorara si provoca problemas de memoria)\n",
    "    if debug:\n",
    "        print(\"ThetasIZ:\",thetas_dict['Theta I_Z'][1])\n",
    "        print(\"ThetasZO:\",thetas_dict['Theta Z_O'][1])\n",
    "        \n",
    "    #print(\"Before:\",thetas_dict['Theta I_Z'][1])\n",
    "    #print((np.amax(thetas_dict['Theta I_Z'])))\n",
    "    thetas_dict['Theta I_Z'] += (X.T.dot(hlayer_smalldelta))\n",
    "    thetas_dict['Theta Z_O'] += fprop_Z2.T.dot(output_smalldelta)\n",
    "    thetas_dict['Theta Z_O'] = thetas_dict['Theta Z_O']/(np.amax(thetas_dict['Theta Z_O']))\n",
    "    #print(\"After:\",thetas_dict['Theta I_Z'][1])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definicion de capa de entrada\n",
    "En este caso utilizamos la suma de los valores de cada linea en la imagen para reducir la cantidad de neuronas en cada capa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-15e24277a023>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#Resheapeamos a y_train para que sea (60k, 1), si no da error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;31m#y_train = y_train[:15000]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0my_train_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "##Definamos la neurona de entrada.\n",
    "#Mi idea es utilizar la suma de los valores de cada pixel en cada linea como mi input layer, reduciendo de 784 neuronas a 28.\n",
    "##Entonces cargamos nuestros datasets de entrenamiento\n",
    "from utils import mnist_reader\n",
    "X_train, y_train = mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "\n",
    "#X_train = X_train[:15000]\n",
    "#print(X_train)\n",
    "#X_train = X_train/(np.amax(X_train))\n",
    "#print(X_train)\n",
    "\n",
    "#Resheapeamos a y_train para que sea (60k, 1), si no da error.\n",
    "\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], 1))\n",
    "#y_train = y_train[:15000]\n",
    "y_train_new = np.zeros((y_train.shape[0], 10))\n",
    "for i in range(len(y_train_new)):\n",
    "    val = y_train[i][0]\n",
    "    y_train_new[i][val] = 1\n",
    "    \n",
    "#print(y_train_new)\n",
    "##Convertimos nuestro X_train de 784 columnas a un X_train_reduced de 28:\n",
    "X_train_reduced = np.zeros((X_train.shape[0], 28))\n",
    "for line in X_train:\n",
    "    X_train_reduced[line] = (np.sum(line.reshape(-1, 28),axis=1))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.9230709  0.69257172 0.31802644 0.56884925 0.3973465  0.25634895\n",
      " 0.08015698 0.71543253 0.41780387 0.57965382]\n"
     ]
    }
   ],
   "source": [
    "#Probemos que hace nuestra funcion feed forward con lo que tenemos.\n",
    "#fprop_res = forward_propagate(X_train_reduced,  sigmoid)\n",
    "#backprop(X_train_reduced, y_train,  fprop_res, sigmoid_derivative, debug=True)\n",
    "#fprop_res = forward_propagate(X_train_reduced,  sigmoid)\n",
    "\n",
    "#print(thetas_dict['Theta Z_O'][1])\n",
    "#Funcionan, creo, entonces probemos repetirlo n veces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcion para entrenar la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, iter=1000, verbose_div=1000,  activation=sigmoid, activation_derivative = sigmoid_derivative):\n",
    "    debug = True\n",
    "    for i in range(iter):\n",
    "        fprop_res = forward_propagate(X,  activation)\n",
    "        backprop(X, y,  fprop_res, sigmoid_derivative, debug)\n",
    "        debug = False\n",
    "        if (i % verbose_div == 0) or (i == iter) :\n",
    "            print(\"Expected output of first 10 samples...\\n\")\n",
    "            print(y[:10])\n",
    "            print(\"Obtained output of first 10 samples...\\n\")\n",
    "            print(fprop_res['Activation'])\n",
    "            print(\"Cost using mean sum squared:\\n\")\n",
    "            print(y - fprop_res['Activation'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [1.73888101 1.63489185 1.36475662 1.93234828 2.14861396 2.1495634\n",
      " 1.00010609 2.12797675 2.22809699 1.29551472]\n",
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99999483 0.99998929 0.99992902 ... 0.99999966 0.99999983 0.99988479]\n",
      " [0.99999483 0.99998929 0.99992902 ... 0.99999966 0.99999983 0.99988479]\n",
      " [0.99999483 0.99998929 0.99992902 ... 0.99999966 0.99999983 0.99988479]\n",
      " ...\n",
      " [0.99773128 0.99673818 0.99164536 ... 0.99941776 0.99958976 0.98937959]\n",
      " [0.99773128 0.99673818 0.99164536 ... 0.99941776 0.99958976 0.98937959]\n",
      " [0.99773128 0.99673818 0.99164536 ... 0.99941776 0.99958976 0.98937959]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99994830e-01 -9.99989291e-01 -9.99929024e-01 ... -9.99999661e-01\n",
      "  -9.99999832e-01  1.15214259e-04]\n",
      " [ 5.17048903e-06 -9.99989291e-01 -9.99929024e-01 ... -9.99999661e-01\n",
      "  -9.99999832e-01 -9.99884786e-01]\n",
      " [ 5.17048903e-06 -9.99989291e-01 -9.99929024e-01 ... -9.99999661e-01\n",
      "  -9.99999832e-01 -9.99884786e-01]\n",
      " ...\n",
      " [-9.97731282e-01 -9.96738179e-01 -9.91645357e-01 ... -9.99417765e-01\n",
      "  -9.99589761e-01 -9.89379595e-01]\n",
      " [ 2.26871803e-03 -9.96738179e-01 -9.91645357e-01 ... -9.99417765e-01\n",
      "  -9.99589761e-01 -9.89379595e-01]\n",
      " [-9.97731282e-01 -9.96738179e-01 -9.91645357e-01 ... -9.99417765e-01\n",
      "  -9.99589761e-01 -9.89379595e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.08425221 0.1197146  0.29956944 0.04436702 0.02252692 0.02246541\n",
      " 1.         0.02396391 0.01787309 0.37838213]\n",
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " ...\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99088242e-01 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01  9.11051194e-04]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " ...\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [ 2.93232825e-02 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.19573566 0.19571484 0.19566279 0.19568361 0.19568361 0.19571484\n",
      " 1.         0.19568361 0.1956732  0.19563155]\n",
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " ...\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99088242e-01 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01  9.11051194e-04]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " ...\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [ 2.93232825e-02 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.19573566 0.19571484 0.19566279 0.19568361 0.19568361 0.19571484\n",
      " 1.         0.19568361 0.1956732  0.19563155]\n",
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " ...\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99088242e-01 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01  9.11051194e-04]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " ...\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [ 2.93232825e-02 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.19573566 0.19571484 0.19566279 0.19568361 0.19568361 0.19571484\n",
      " 1.         0.19568361 0.1956732  0.19563155]\n",
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " ...\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99088242e-01 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01  9.11051194e-04]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " ...\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [ 2.93232825e-02 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.19573566 0.19571484 0.19566279 0.19568361 0.19568361 0.19571484\n",
      " 1.         0.19568361 0.1956732  0.19563155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " ...\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99088242e-01 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01  9.11051194e-04]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " ...\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [ 2.93232825e-02 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.19573566 0.19571484 0.19566279 0.19568361 0.19568361 0.19571484\n",
      " 1.         0.19568361 0.1956732  0.19563155]\n",
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " ...\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99088242e-01 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01  9.11051194e-04]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " ...\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [ 2.93232825e-02 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.19573566 0.19571484 0.19566279 0.19568361 0.19568361 0.19571484\n",
      " 1.         0.19568361 0.1956732  0.19563155]\n",
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " ...\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99088242e-01 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01  9.11051194e-04]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " ...\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [ 2.93232825e-02 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.19573566 0.19571484 0.19566279 0.19568361 0.19568361 0.19571484\n",
      " 1.         0.19568361 0.1956732  0.19563155]\n",
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " ...\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99088242e-01 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01  9.11051194e-04]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " ...\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [ 2.93232825e-02 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.19573566 0.19571484 0.19566279 0.19568361 0.19568361 0.19571484\n",
      " 1.         0.19568361 0.1956732  0.19563155]\n",
      "Expected output of first 10 samples...\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Obtained output of first 10 samples...\n",
      "\n",
      "[[0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " [0.99908824 0.99908838 0.99908874 ... 0.9990886  0.99908867 0.99908895]\n",
      " ...\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]\n",
      " [0.97067672 0.97067893 0.97068445 ... 0.97068224 0.97068335 0.97068777]]\n",
      "Cost using mean sum squared:\n",
      "\n",
      "[[-9.99088242e-01 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01  9.11051194e-04]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " [ 9.11758435e-04 -9.99088383e-01 -9.99088737e-01 ... -9.99088595e-01\n",
      "  -9.99088666e-01 -9.99088949e-01]\n",
      " ...\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [ 2.93232825e-02 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]\n",
      " [-9.70676718e-01 -9.70678927e-01 -9.70684452e-01 ... -9.70682242e-01\n",
      "  -9.70683347e-01 -9.70687769e-01]]\n",
      "ThetasIZ: [0.68949079 0.96295812 0.03855362 0.84317888 0.53962812 0.56846409\n",
      " 0.79099495]\n",
      "ThetasZO: [0.19573566 0.19571484 0.19566279 0.19568361 0.19568361 0.19571484\n",
      " 1.         0.19568361 0.1956732  0.19563155]\n"
     ]
    }
   ],
   "source": [
    "train(X_train_reduced, y_train_new, iter=1000,verbose_div=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creamos los sets de prueba con la misma forma que el de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "y_test = np.reshape(y_test, (y_test.shape[0], 1))\n",
    "y_test_new = np.zeros((y_test.shape[0], 10))\n",
    "for i in range(len(y_test_new)):\n",
    "    val = y_test[i][0]\n",
    "    y_test_new[i][val] = 1\n",
    "    \n",
    "\n",
    "X_test_reduced = np.zeros((X_test.shape[0], 28))\n",
    "for line in X_train:\n",
    "    X_test_reduced[line] = (np.sum(line.reshape(-1, 28),axis=1))\n",
    "print(X_test.shape, y_test_new.shape)\n",
    "np.savetxt(\"xred.txt\", X_test_reduced)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Se prueban los valores y se normaliza el output para poner encontrar cuales cazan con el valor esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = forward_propagate(X_test_reduced)\n",
    "activated = test_values['Activation']\n",
    "activated_norm = np.zeros(activated.shape)\n",
    "for i in range(len(activated)):\n",
    "    activated_norm[i] = activated[i]/np.amax(activated[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_2_mnist",
   "language": "python",
   "name": "lab_2_mnist"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
